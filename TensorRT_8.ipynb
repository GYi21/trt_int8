{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "calibration_data_path = \"/home/guoy/led_detection/training/yolov8/yolo_val/extra_npy\"\n",
    "files = sorted([os.path.join(calibration_data_path, f) for f in os.listdir(calibration_data_path) if f.endswith(\".npy\")])\n",
    "\n",
    "for f in files[:5]:  # 只检查前5个\n",
    "    data = np.load(f)\n",
    "    print(f\"检查 {f}: shape={data.shape}, dtype={data.dtype}, min={data.min()}, max={data.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/14/2025-14:44:46] [TRT] [I] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 35, GPU 842 (MiB)\n",
      "[03/14/2025-14:44:48] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2175, GPU +418, now: CPU 2365, GPU 1260 (MiB)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__(self, ...) called with invalid or missing `self` argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m calibration_data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/guoy/led_detection/training/yolov8/yolo_val/extra_npy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your .npy files\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# 正确的方式：直接赋值 int8_calibrator\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m config\u001b[38;5;241m.\u001b[39mint8_calibrator \u001b[38;5;241m=\u001b[39m \u001b[43mCalibrator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalibration_data_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Set dynamic input and output shape ranges\u001b[39;00m\n\u001b[1;32m     84\u001b[0m profile \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_optimization_profile()\n",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m, in \u001b[0;36mCalibrator.__init__\u001b[0;34m(self, calibration_data_path, batch_size, cache_file)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, calibration_data_path, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,cache_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/opt/projects/aoi/led_detection/training/models/RT_DETR/INT8/calibration.cache\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m#set the batch size\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIInt8EntropyCalibrator2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m calibration_data_path\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__(self, ...) called with invalid or missing `self` argument"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import os\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "onnx_model_path = \"RetinaNet_v1.onnx\"\n",
    "trt_engine_path = \"RetinaNet_16_int8.trt\"\n",
    "\n",
    "# Create a logger for TensorRT\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# Create TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "\n",
    "# Load and parse the ONNX model\n",
    "with open(onnx_model_path, \"rb\") as model_file:\n",
    "    if not parser.parse(model_file.read()):\n",
    "        print(\"❌ Failed to parse the ONNX model!\")\n",
    "        for error in range(parser.num_errors):\n",
    "            print(f\"Error {error}: {parser.get_error(error)}\")\n",
    "        exit(1)\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 8 << 30)  # Set 8GB workspace size\n",
    "\n",
    "# Enable INT8 precision\n",
    "config.set_flag(trt.BuilderFlag.INT8)  # Enable INT8 precision\n",
    "\n",
    "# Provide the INT8 calibrator\n",
    "class Calibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, calibration_data_path, batch_size=1): #set the batch size\n",
    "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = calibration_data_path\n",
    "        self.data_files = sorted(os.listdir(calibration_data_path))  \n",
    "        self.current_index = 0\n",
    "        self.device_input = None\n",
    "        self.cache_file = cache_file\n",
    "        \n",
    "        # Preloaded calibration data\n",
    "        self.data = []\n",
    "        for file in self.data_files:\n",
    "            file_path = os.path.join(calibration_data_path, file)\n",
    "            img = np.load(file_path,allow_pickle=True)  # load the  the calibration data （.npy Format）\n",
    "            self.data.append(img)\n",
    "        \n",
    "        self.device_input = cuda.mem_alloc(self.batch_size * self.data[0].nbytes)  \n",
    "\n",
    "    \n",
    "    def get_batch(self, names):\n",
    "        if self.current_index + self.batch_size > len(self.data):\n",
    "            return None  \n",
    "        batch = np.ascontiguousarray(self.data[self.current_index:self.current_index + self.batch_size])\n",
    "        cuda.memcpy_htod(self.device_input, batch)\n",
    "        self.current_index += self.batch_size\n",
    "        return [self.device_input]\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def read_calibration_cache(self):\n",
    "        # 可选：加载已存在的校准缓存\n",
    "        return None\n",
    "\n",
    "    def write_calibration_cache(self, cache):\n",
    "        # 可选：保存校准缓存\n",
    "        pass\n",
    "\n",
    "    def get_algorithm(self):\n",
    "        \"\"\" 必须实现此方法，否则会报错 \"\"\"\n",
    "        return trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2  # 选择合适的量化算法\n",
    "\n",
    "\n",
    "# Assuming you have a folder with calibration data in .npy format\n",
    "calibration_data_folder = \"/home/guoy/led_detection/training/yolov8/yolo_val/extra_npy\"  # Path to your .npy files\n",
    "\n",
    "# 正确的方式：直接赋值 int8_calibrator\n",
    "config.int8_calibrator = Calibrator(calibration_data_folder)\n",
    "\n",
    "# Set dynamic input and output shape ranges\n",
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape(\"input\", (1, 3, 640, 640), (1, 3, 640, 640), (1, 3, 640, 640))  # Fixed input shape\n",
    "\n",
    "# Set dynamic shape range for the output tensors\n",
    "profile.set_shape(\"scores\", (1,), (18,), (300,))  # Minimum 1 detection, maximum 300 detections\n",
    "profile.set_shape(\"labels\", (1,), (18,), (300,))\n",
    "profile.set_shape(\"boxes\", (1, 4), (18, 4), (300, 4))\n",
    "\n",
    "config.add_optimization_profile(profile)\n",
    "\n",
    "# Build the TensorRT engine\n",
    "print(\"🚀 Building TensorRT engine, please wait...\")\n",
    "engine = builder.build_serialized_network(network, config)\n",
    "if engine is None:\n",
    "    print(\"❌ Failed to build the TensorRT engine!\")\n",
    "    exit(1)\n",
    "\n",
    "# Save the engine to a file\n",
    "\n",
    "with open(trt_engine_path, \"wb\") as f:\n",
    "    f.write(engine)\n",
    "print(f\"✅ TensorRT engine has been saved to {trt_engine_path}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
